{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install keras==2.2.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom __future__ import print_function, division\n\nfrom keras.applications.vgg19 import VGG19\nfrom keras.layers import Input, Dense, Flatten, Dropout, Reshape\nfrom keras.layers import BatchNormalization, Activation, Conv2D, Conv2DTranspose\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\n\nfrom keras.datasets import cifar10\nimport keras.backend as K\nimport tensorflow as tf\nfrom tensorflow.python.keras import backend as K\nfrom keras.models import load_model\n\nimport matplotlib.pyplot as plt\n\nimport sys\nimport numpy as np\n\n%pylab inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install keras_vggface","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras_applications.imagenet_utils import _obtain_input_shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras_vggface import VGGFace","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_generator(input_layer):\n \n  hid = Dense(128 * 32 * 32, activation='relu')(input_layer)    \n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n  hid = Reshape((32, 32, 128))(hid)\n\n  hid = Conv2D(128, kernel_size=5, strides=1,padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)    \n  #hid = Dropout(0.5)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n\n  hid = Conv2DTranspose(128, 4, strides=2, padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n\n  hid = Conv2DTranspose(128, 4, strides=2, padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n\n  hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  #hid = Dropout(0.5)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n\n  hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n                      \n  hid = Conv2D(3, kernel_size=5, strides=1, padding=\"same\")(hid)\n  out = Activation(\"tanh\")(hid)\n  model = Model(input_layer, out)\n  model.summary()\n  \n  return model, out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_discriminator(input_layer):\n  '''\n  Requires the input layer as input, outputs the model and the final layer\n  '''\n  vgg_model = VGGFace(include_top=False, input_shape=(128, 128, 3))\n  nb_class = 1\n  hidden_dim = 512\n  for layer in vgg_model.layers[:9]:\n    layer.trainable=False\n  last_layer = vgg_model.output\n  x = Flatten(name='flatten')(last_layer)\n  x = Dense(hidden_dim,name='fc6')(x)\n  x = LeakyReLU(alpha=0.1)(x)\n  #x = Dense(128,name='fc7')(x)\n  #x = LeakyReLU(alpha=0.1)(x)\n  out = Dense(nb_class, activation='sigmoid', name='fc8')(x)  \n\n  model = Model(vgg_model.input, out)\n\n  model.summary()\n\n  return model, out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\n\ndef generate_noise(n_samples, noise_dim):\n  X = np.random.normal(0, 1, size=(n_samples, noise_dim))\n  return X\n\ndef show_imgs(batchidx):\n  noise = generate_noise(9, 100)\n  gen_imgs = generator.predict(noise)\n\n  fig, axs = plt.subplots(3, 3)\n  count = 0\n  for i in range(3):\n    for j in range(3):\n      img = image.array_to_img(gen_imgs[count], scale=True)\n      axs[i,j].imshow(img)\n      axs[i,j].axis('off')\n      count += 1\n  plt.show()\n  plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GAN creation\nimg_input = Input(shape=(128,128,3))\ndiscriminator, disc_out = get_discriminator(img_input)\ndiscriminator.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])\n\ndiscriminator.trainable = False\n\nnoise_input = Input(shape=(100,))\ngenerator, gen_out = get_generator(noise_input)\n\ngan_input = Input(shape=(100,))\nx = generator(gan_input)\ngan_out = discriminator(x)\ngan = Model(gan_input, gan_out)\ngan.summary()\n\ngan.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data\nBASE_PATH = \"../input/celebrities-100k/\"\nprint(os.listdir(BASE_PATH))\n#BASE_PATH = base_PATH+ 'celebrities-100k' \nDATASET_LIST_PATH= BASE_PATH + \"100k.txt\"\nprint(DATASET_LIST_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_DATA_DIR = BASE_PATH + \"100k/100k/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OUTPUT_DIR = \"./\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#MODEL_PATH = BASE_PATH + \"models/\" + \"model_\" + str(EPOCH) + \".ckpt\"\nDATASET = [INPUT_DATA_DIR + str(line).rstrip() for line in open(DATASET_LIST_PATH,\"r\")]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(DATASET)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=DATASET[:10000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.misc\nimport scipy.ndimage","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#uploading images from folder\nimages = []\nfor img_name in data:\n    image = scipy.ndimage.imread(img_name, mode=\"RGB\")\n    image_resized = scipy.misc.imresize(image,(128,128))\n    images.append(image_resized)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = np.stack(images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = ((X_train)-127.5)/127.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nBATCH_SIZE = 64\n\n# # Get training images\n#(X_train, y_train), (X_test, _) = cifar10.load_data()\n\n# S\n\n# Normalize data\n \nnum_batches = int(X_train.shape[0]/BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N_EPOCHS = 200\nCUMM_DLOSS=0\nfor epoch in range(N_EPOCHS):\n  tic=time.time()\n  cum_d_loss = 0.\n  cum_g_loss = 0.\n  \n  for batch_idx in range(num_batches):\n    # Get the next set of real images to be used in this iteration\n    images = X_train[batch_idx*BATCH_SIZE : (batch_idx+1)*BATCH_SIZE]\n\n    noise_data = generate_noise(BATCH_SIZE, 100)\n    generated_images = generator.predict(noise_data)\n\n    # Train on soft labels (add noise to labels as well)\n    noise_prop = 0.05 # Randomly flip 5% of labels\n    \n    # Prepare labels for real data\n    true_labels = np.zeros((BATCH_SIZE, 1)) + np.random.uniform(low=0.0, high=0.1, size=(BATCH_SIZE, 1))\n    flipped_idx = np.random.choice(np.arange(len(true_labels)), size=int(noise_prop*len(true_labels)))\n    true_labels[flipped_idx] = 1 - true_labels[flipped_idx]\n    \n    # Train discriminator on real data\n    d_loss_true = discriminator.train_on_batch(images, true_labels)\n\n    # Prepare labels for generated data\n    gene_labels = np.ones((BATCH_SIZE, 1)) - np.random.uniform(low=0.0, high=0.1, size=(BATCH_SIZE, 1))\n    flipped_idx = np.random.choice(np.arange(len(gene_labels)), size=int(noise_prop*len(gene_labels)))\n    gene_labels[flipped_idx] = 1 - gene_labels[flipped_idx]\n    # Train discriminator on generated data\n    d_loss_gene = discriminator.train_on_batch(generated_images, gene_labels)\n\n    d_loss = 0.5*np.add(d_loss_true, d_loss_gene)\n    cum_d_loss += d_loss\n    # Train generator\n    noise_data = generate_noise(BATCH_SIZE, 100)\n    g_loss = gan.train_on_batch(noise_data, np.zeros((BATCH_SIZE, 1)))\n    cum_g_loss += g_loss\n\n  #for whole data:-\n  IMAGES=X_train \n  Noise_Data = generate_noise(10000, 100)\n  Generated_Images = generator.predict(Noise_Data)\n  # Prepare labels for real data\n  True_Labels = np.zeros((10000, 1)) + np.random.uniform(low=0.0, high=0.1, size=(10000, 1))\n  Flipped_Idx = np.random.choice(np.arange(len(True_Labels)), size=int(noise_prop*len(True_Labels)))\n  True_Labels[Flipped_Idx] = 1 - True_Labels[Flipped_Idx]\n  \n  # EVALUATE discriminator on real data\n  DLOSS_TRUE = discriminator.evaluate(IMAGES, True_Labels) \n\n  # Prepare labels for generated data\n  Gene_Labels = np.ones((10000, 1)) - np.random.uniform(low=0.0, high=0.1, size=(10000, 1))\n  Flipped_Idx = np.random.choice(np.arange(len(Gene_Labels)), size=int(noise_prop*len(Gene_Labels)))\n  Gene_Labels[Flipped_Idx] = 1 - Gene_Labels[Flipped_Idx]\n  # EVALUTE discriminator on generated data\n  D_LOSS_GENE = discriminator.evaluate(Generated_Images, Gene_Labels) \n  D_LOSS=0.5*np.add(DLOSS_TRUE,D_LOSS_GENE)\n  CUMM_DLOSS+=D_LOSS\n   \n  print(\"  Epoch:- \"+str(epoch+1)+\", D LOSS: \"+str(D_LOSS) + \"; Cummulative D_LOSS: \"+ str(CUMM_DLOSS) )\n    \n  \n  noise_data = generate_noise(BATCH_SIZE, 100)\n  #generated_images = generator.predict(noise_data)\n  print('  Epoch: {}, Generator Loss: {}, Discriminator Loss: {}'.format(epoch+1, cum_g_loss/num_batches, cum_d_loss/num_batches))\n  show_imgs(\"epoch\" + str(epoch))\n  toc=time.time()\n  print(\"For epoch: \"+ str(epoch +1)+\", Time taken is: \" +str(toc-tic)+ \" seconds\")\n  #print(discriminator.predict(generated_images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}
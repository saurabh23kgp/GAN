{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from __future__ import print_function, division\nfrom keras.layers import Input, Dense, Flatten, Dropout, Reshape, Concatenate\nfrom keras.layers import BatchNormalization, Activation, Conv2D, Conv2DTranspose\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.datasets import mnist\nimport keras.backend as K\nimport matplotlib.pyplot as plt\nimport sys\nimport numpy as np\n%pylab inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"#Creating Generator for CGANS\ndef get_generator(input_layer, condition_layer):\n\n  merged_input = Concatenate()([input_layer, condition_layer])#concatenating (100,) tensor with (10,1) tensor\n  hid = Dense(128 * 7 * 7, activation='relu')(merged_input)    \n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n  hid = Reshape((7, 7, 128))(hid)\n  hid = Conv2D(128, kernel_size=4, strides=1,padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)    \n  hid = LeakyReLU(alpha=0.1)(hid)\n  hid = Conv2DTranspose(128, 4, strides=2, padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n  hid = Conv2D(128, kernel_size=5, strides=1,padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)    \n  hid = LeakyReLU(alpha=0.1)(hid)\n  hid = Conv2DTranspose(128, 4, strides=2, padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n  hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n  hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)        \n  hid = Conv2D(1, kernel_size=5, strides=1, padding=\"same\")(hid)\n  out = Activation(\"tanh\")(hid)\n  model = Model(inputs=[input_layer, condition_layer], outputs=out)\n  model.summary()\n  return model, out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating Discriminator for CGANS\ndef get_discriminator(input_layer, condition_layer):\n    \n  hid = Conv2D(128, kernel_size=3, strides=1, padding='same')(input_layer)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n  hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n  hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n  hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n  hid = Flatten()(hid)\n  merged_layer = Concatenate()([hid, condition_layer])\n  hid = Dense(512, activation='relu')(merged_layer)\n  hid = Dropout(0.4)(hid)\n  out = Dense(1, activation='sigmoid')(hid)\n  model = Model(inputs=[input_layer, condition_layer], outputs=out)\n  model.summary()\n  return model, out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\n\n#making one_hot_encoder function to get encoders\ndef one_hot_encode(y):\n  z = np.zeros((len(y), 10))\n  idx = np.arange(len(y))\n  z[idx, y] = 1\n  return z\n\n#function to make a latent space vector\ndef generate_noise(n_samples, noise_dim):\n  X = np.random.normal(0, 1, size=(n_samples, noise_dim))\n  return X\n\n#function to return one hot encoders corresponding to labels\ndef generate_random_labels(n):\n  y = np.random.choice(10, n)\n  y = one_hot_encode(y)\n  return y\n\ntags = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n \n#function to generate/print images from generator\ndef show_samples(batchidx):\n  fig, axs = plt.subplots(5, 6, figsize=(10,6))\n  plt.subplots_adjust(hspace=0.3, wspace=0.1)\n    \n  for classlabel in range(10):\n    row = int(classlabel / 2)\n    coloffset = (classlabel % 2) * 3\n    lbls = one_hot_encode([classlabel] * 3)\n    noise = generate_noise(3, 100)\n    gen_imgs = generator.predict([noise, lbls])\n\n    for i in range(3):\n        img = image.array_to_img(gen_imgs[i], scale=True)\n        axs[row,i+coloffset].imshow(img)\n        axs[row,i+coloffset].axis('off')\n        if i ==1:\n          axs[row,i+coloffset].set_title(tags[classlabel])\n  plt.show()\n  plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating tensors for input images and labels(next 2 lines)\nimg_input = Input(shape=(28,28,1))\ndisc_condition_input = Input(shape=(10,))\ndiscriminator, disc_out = get_discriminator(img_input, disc_condition_input)  #'discrminator' will store the model. From now on, we will just need 'dicriminator' from this line for further compilations and classification of fake and real images\ndiscriminator.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])       \ndiscriminator.trainable = False                                                                            \nnoise_input = Input(shape=(100,))    #creating tensor                                                                     \ngen_condition_input = Input(shape=(10,)) #creating tensor                                                                 \ngenerator, gen_out = get_generator(noise_input, gen_condition_input)\ngan_input = Input(shape=(100,))#creating tensor\nx = generator([gan_input, gen_condition_input])#feeding random noise/latent space vector and label in 'generator'\ngan_out = discriminator([x, disc_condition_input])#whatever comes out of generator after executing the previous line is fed into discriminator along with the labels\ngan = Model(inputs=[gan_input, gen_condition_input, disc_condition_input], output=gan_out)#Feeding the above found values into the GAN for both discriminator and generator weights to learn\ngan.summary()\ngan.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating batchsize, importing dataset from keras library, converting target labels to one hot encoded labels\nBATCH_SIZE = 100\n(X_train, y_train), (X_test, _) = mnist.load_data()\nX_train = (X_train - 127.5) / 127.5\ny_train = one_hot_encode(y_train[:])\nprint (\"Training shape: {}\".format(X_train.shape))\nnum_batches = int(X_train.shape[0]/BATCH_SIZE) # number of batches is number of training examples (as given by X_train.shape[0]) divided by batchsize","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=X_train\nx = x.reshape((60000, 28, 28, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating an array to store images for experience replay\nexp_replay = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N_EPOCHS = 100 #number of epochs\nfor epoch in range(N_EPOCHS):\n  cum_d_loss = 0.\n  cum_g_loss = 0.\n  for batch_idx in range(num_batches):\n    images = X_train[batch_idx*BATCH_SIZE : (batch_idx+1)*BATCH_SIZE]\n    labels = y_train[batch_idx*BATCH_SIZE : (batch_idx+1)*BATCH_SIZE]\n    noise_data = generate_noise(BATCH_SIZE, 100)\n    random_labels = generate_random_labels(BATCH_SIZE)\n    generated_images = generator.predict([noise_data, labels])\n    noise_prop = 0.05 \n    true_labels = np.zeros((BATCH_SIZE, 1)) + np.random.uniform(low=0.0, high=0.1, size=(BATCH_SIZE, 1))\n    flipped_idx = np.random.choice(np.arange(len(true_labels)), size=int(noise_prop*len(true_labels)))\n    true_labels[flipped_idx] = 1 - true_labels[flipped_idx]\n    d_loss_true = discriminator.train_on_batch([images, labels], true_labels)\n    gene_labels = np.ones((BATCH_SIZE, 1)) - np.random.uniform(low=0.0, high=0.1, size=(BATCH_SIZE, 1))\n    flipped_idx = np.random.choice(np.arange(len(gene_labels)), size=int(noise_prop*len(gene_labels)))\n    gene_labels[flipped_idx] = 1 - gene_labels[flipped_idx]\n    d_loss_gene = discriminator.train_on_batch([generated_images, labels], gene_labels)\n    r_idx = np.random.randint(BATCH_SIZE)\n    exp_replay.append([generated_images[r_idx], labels[r_idx], gene_labels[r_idx]])\n    if len(exp_replay) == BATCH_SIZE:\n      generated_images = np.array([p[0] for p in exp_replay])\n      labels = np.array([p[1] for p in exp_replay])\n      gene_labels = np.array([p[2] for p in exp_replay])\n      expprep_loss_gene = discriminator.train_on_batch([generated_images, labels], gene_labels)\n      exp_replay = []\n      break\n    d_loss = 0.5 * np.add(d_loss_true, d_loss_gene)\n    cum_d_loss += d_loss\n    noise_data = generate_noise(BATCH_SIZE, 100)\n    random_labels = generate_random_labels(BATCH_SIZE)\n    g_loss = gan.train_on_batch([noise_data, random_labels, random_labels], np.zeros((BATCH_SIZE, 1)))\n    cum_g_loss += g_loss\n  print('\\tEpoch: {}, Generator Loss: {}, Discriminator Loss: {}'.format(epoch+1, cum_g_loss/num_batches, cum_d_loss/num_batches))\n  show_samples(\"epoch\" + str(epoch))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}
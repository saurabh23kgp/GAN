{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from __future__ import print_function, division\n\nfrom keras.layers import Input, Dense, Flatten, Dropout, Reshape\nfrom keras.layers import BatchNormalization, Activation, Conv2D, Conv2DTranspose\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Model\nfrom keras.optimizers import Adam\n\n\nfrom keras.datasets import cifar10\nimport keras.backend as K\n\nimport matplotlib.pyplot as plt\n\nimport sys\nimport numpy as np\n\n%pylab inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"def get_generator(input_layer):\n \n  hid = Dense(128 * 16 * 16, activation='relu')(input_layer)    \n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n  hid = Reshape((16, 16, 128))(hid)\n\n  hid = Conv2D(128, kernel_size=5, strides=1,padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)    \n  #hid = Dropout(0.5)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n\n  hid = Conv2DTranspose(128, 4, strides=2, padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n\n  hid = Conv2DTranspose(128, 4, strides=2, padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n\n  hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  #hid = Dropout(0.5)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n\n  hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n                      \n  hid = Conv2D(3, kernel_size=5, strides=1, padding=\"same\")(hid)\n  out = Activation(\"tanh\")(hid)\n\n  model = Model(input_layer, out)\n  model.summary()\n  \n  return model, out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_discriminator(input_layer):\n\n  hid = Conv2D(128, kernel_size=3, strides=1, padding='same')(input_layer)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n\n  hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n\n  hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n\n  hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n  hid = BatchNormalization(momentum=0.9)(hid)\n  hid = LeakyReLU(alpha=0.1)(hid)\n\n  hid = Flatten()(hid)\n  hid = Dropout(0.4)(hid)\n  out = Dense(1, activation='sigmoid')(hid)\n\n  model = Model(input_layer, out)\n\n  model.summary()\n\n  return model, out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\n\ndef generate_noise(n_samples, noise_dim):\n  X = np.random.normal(0, 1, size=(n_samples, noise_dim))\n  return X\n\ndef show_imgs(batchidx):\n  noise = generate_noise(9, 100)\n  gen_imgs = generator.predict(noise)\n\n  fig, axs = plt.subplots(3, 3)\n  count = 0\n  for i in range(3):\n    for j in range(3):\n      img = image.array_to_img(gen_imgs[count], scale=True)\n      axs[i,j].imshow(img)\n      axs[i,j].axis('off')\n      count += 1\n  plt.show()\n  plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GAN creation\nimg_input = Input(shape=(64,64,3))\ndiscriminator, disc_out = get_discriminator(img_input)\ndiscriminator.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])\n\ndiscriminator.trainable = False\n\nnoise_input = Input(shape=(100,))\ngenerator, gen_out = get_generator(noise_input)\n\ngan_input = Input(shape=(100,))\nx = generator(gan_input)\ngan_out = discriminator(x)\ngan = Model(gan_input, gan_out)\ngan.summary()\n\ngan.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data\nBASE_PATH = \"../input/\"\nprint(os.listdir(BASE_PATH))\nDATASET_LIST_PATH = BASE_PATH + \"100k.txt\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_DATA_DIR = BASE_PATH + \"100k/100k/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OUTPUT_DIR = \"./\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#MODEL_PATH = BASE_PATH + \"models/\" + \"model_\" + str(EPOCH) + \".ckpt\"\nDATASET = [INPUT_DATA_DIR + str(line).rstrip() for line in open(DATASET_LIST_PATH,\"r\")]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#uploading images from folder\nimages = []\nfor img_name in DATASET:\n    image = scipy.ndimage.imread(img_name, mode=\"RGB\")\n    image_resized = scipy.misc.imresize(image,(64,64))\n    images.append(image_resized)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = np.stack(images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_x[:50000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = ((X_train)-127.5)/127.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TCH_SIZE = 320\n\n# Normalize data\n \nnum_batches = int(X_train.shape[0]/BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N_EPOCHS = 60\nfor epoch in range(N_EPOCHS):\n\n  cum_d_loss = 0.\n  cum_g_loss = 0.\n  \n  for batch_idx in range(num_batches):\n    # Get the next set of real images to be used in this iteration\n    images = X_train[batch_idx*BATCH_SIZE : (batch_idx+1)*BATCH_SIZE]\n\n    noise_data = generate_noise(BATCH_SIZE, 100)\n    generated_images = generator.predict(noise_data)\n\n    # Train on soft labels (add noise to labels as well)\n    noise_prop = 0.05 # Randomly flip 5% of labels\n    \n    # Prepare labels for real data\n    true_labels = np.zeros((BATCH_SIZE, 1)) + np.random.uniform(low=0.0, high=0.1, size=(BATCH_SIZE, 1))\n    flipped_idx = np.random.choice(np.arange(len(true_labels)), size=int(noise_prop*len(true_labels)))\n    true_labels[flipped_idx] = 1 - true_labels[flipped_idx]\n    \n    # Train discriminator on real data\n    d_loss_true = discriminator.train_on_batch(images, true_labels)\n\n    # Prepare labels for generated data\n    gene_labels = np.ones((BATCH_SIZE, 1)) - np.random.uniform(low=0.0, high=0.1, size=(BATCH_SIZE, 1))\n    flipped_idx = np.random.choice(np.arange(len(gene_labels)), size=int(noise_prop*len(gene_labels)))\n    gene_labels[flipped_idx] = 1 - gene_labels[flipped_idx]\n    \n    # Train discriminator on generated data\n    d_loss_gene = discriminator.train_on_batch(generated_images, gene_labels)\n\n    d_loss = 0.5 * np.add(d_loss_true, d_loss_gene)\n    cum_d_loss += d_loss\n    # Train generator\n    noise_data = generate_noise(BATCH_SIZE, 100)\n    g_loss = gan.train_on_batch(noise_data, np.zeros((BATCH_SIZE, 1)))\n    cum_g_loss += g_loss\n    \n  noise_data = generate_noise(BATCH_SIZE, 100)\n  generated_images = generator.predict(noise_data)\n  print('  Epoch: {}, Generator Loss: {}, Discriminator Loss: {}'.format(epoch+1, cum_g_loss/num_batches, cum_d_loss/num_batches))\n  show_imgs(\"epoch\" + str(epoch))\n  print(discriminator.predict(generated_images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}
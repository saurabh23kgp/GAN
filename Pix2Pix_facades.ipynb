{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from __future__ import absolute_import, division, print_function, unicode_literals\n\n!pip install tensorflow-gpu==2.0.0-beta1\nimport tensorflow as tf\n\nimport os\nimport time\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load(image_file):\n  image = tf.io.read_file(image_file)\n  image = tf.image.decode_jpeg(image)\n\n  w = tf.shape(image)[1]\n\n  w = w // 2\n  real_image = image[:, :w, :]\n  input_image = image[:, w:, :]\n\n  input_image = tf.cast(input_image, tf.float32)\n  real_image = tf.cast(real_image, tf.float32)\n\n  return input_image, real_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BUFFER_SIZE = 400\nBATCH_SIZE = 1\nIMG_WIDTH = 256\nIMG_HEIGHT = 256","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path='../input/dataset/facades'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"facade_train=[f for f in os.listdir(os.path.join(path, 'train'))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(facade_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.misc\nimport scipy.ndimage","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_images=[]\nreal_images=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.misc\nimport scipy.ndimage","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\ndef rgb2gray(rgb):\n    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n\nfor img in facade_train:\n    final_path=os.path.join('../input/dataset/facades/train',img)\n    inp, re = load(final_path)\n    inp=rgb2gray(inp)\n    inp=np.array(inp)\n    input_images.append(inp)\n    re=rgb2gray(re)\n    re=np.array(re)\n    real_images.append(re)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize_bw_image(img):\n    \"\"\"\n    Visualize a black and white image\n    \"\"\"\n    img= img.squeeze()\n\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1)\n    ax.imshow(img, cmap='gray', interpolation='nearest')\n    ax.axis(\"off\")\n    ax.set_title(\"Image\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_images=np.stack(real_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_images=real_images.reshape((400, 256, 256, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_images = ((real_images)-127.5)/127.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_images=np.stack(input_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_images=input_images.reshape((400, 256, 256, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_images = ((input_images)-127.5)/127.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_images[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_bw_image(real_images[0]/255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_bw_image(input_images[0]/255.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_facade_photos=real_images\ntraining_facade_labels=input_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path='../input/dataset/facades'\nfacade_test=[f for f in os.listdir(os.path.join(path, 'test'))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_images=[]\nreal_images=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\ndef rgb2gray(rgb):\n    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n\nfor img in facade_test:\n    final_path=os.path.join('../input/dataset/facades/test',img)\n    inp, re = load(final_path)\n    inp=np.array(inp)\n    inp=rgb2gray(inp)\n    input_images.append(inp)\n    re=np.array(re)\n    re=rgb2gray(re)\n    real_images.append(re)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_bw_image(real_images[0]/255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_bw_image(input_images[0]/255.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_images=np.stack(real_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_images=np.stack(input_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_images.shape\ninput_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_images=real_images.reshape((106, 256, 256, 1))\ninput_images=input_images.reshape((106, 256, 256, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_images = ((real_images)-127.5)/127.5\ninput_images = ((input_images)-127.5)/127.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_facade_photos=real_images\ntest_facade_labels=input_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path='../input/dataset/facades'\nfacade_val=[f for f in os.listdir(os.path.join(path, 'val'))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_images=[]\nreal_images=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\ndef rgb2gray(rgb):\n    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n\nfor img in facade_val:\n    final_path=os.path.join('../input/dataset/facades/val',img)\n    inp, re = load(final_path)\n    inp=np.array(inp)\n    inp=rgb2gray(inp)\n    input_images.append(inp)\n    re=np.array(re)\n    re=rgb2gray(re)\n    real_images.append(re)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_images=np.stack(real_images)\ninput_images=np.stack(input_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_images=real_images.reshape((100, 256, 256, 1))\ninput_images=input_images.reshape((100, 256, 256, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_images = ((real_images)-127.5)/127.5\ninput_images = ((input_images)-127.5)/127.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_facade_photos=real_images\nvalidation_facade_labels=input_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install tensorflow==1.13.1\n#!pip install keras==2.0.9\n#!pip install -q tensorflow==2.0.0-alpha0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorboard==1.13.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport time\n\nimport h5py\nimport tensorflow.keras.backend as K\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom cv2 import imwrite\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.callbacks import TensorBoard\nfrom tensorflow.keras.layers import Convolution2D, LeakyReLU, BatchNormalization, UpSampling2D, Dropout, Activation, Flatten,  Dense, Lambda, Reshape, concatenate\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_unet_generator():\n    \"\"\"\n    Create the U-Net Generator using the hyperparameter values defined below\n    \"\"\"\n    kernel_size = 4\n    strides = 2\n    leakyrelu_alpha = 0.2\n    upsampling_size = 2\n    dropout = 0.4\n    output_channels = 1\n    input_shape = (256, 256, 1)\n\n    input_layer = Input(shape=input_shape)\n\n    # Encoder Network\n\n    # 1st Convolutional block in the encoder network\n    encoder1 = Convolution2D(filters=64, kernel_size=kernel_size, padding='same',\n                             strides=strides)(input_layer)\n    encoder1 = LeakyReLU(alpha=leakyrelu_alpha)(encoder1)\n\n    # 2nd Convolutional block in the encoder network\n    encoder2 = Convolution2D(filters=128, kernel_size=kernel_size, padding='same',\n                             strides=strides)(encoder1)\n    encoder2 = BatchNormalization()(encoder2)\n    encoder2 = LeakyReLU(alpha=leakyrelu_alpha)(encoder2)\n    # 3rd Convolutional block in the encoder network\n    encoder3 = Convolution2D(filters=256, kernel_size=kernel_size, padding='same',\n                             strides=strides)(encoder2)\n    encoder3 = BatchNormalization()(encoder3)\n    encoder3 = LeakyReLU(alpha=leakyrelu_alpha)(encoder3)\n\n    # 4th Convolutional block in the encoder network\n    encoder4 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same',\n                             strides=strides)(encoder3)\n    encoder4 = BatchNormalization()(encoder4)\n    encoder4 = LeakyReLU(alpha=leakyrelu_alpha)(encoder4)\n\n    # 5th Convolutional block in the encoder network\n    encoder5 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same',\n                             strides=strides)(encoder4)\n    encoder5 = BatchNormalization()(encoder5)\n    encoder5 = LeakyReLU(alpha=leakyrelu_alpha)(encoder5)\n\n    # 6th Convolutional block in the encoder network\n    encoder6 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same',\n                             strides=strides)(encoder5)\n    encoder6 = BatchNormalization()(encoder6)\n    encoder6 = LeakyReLU(alpha=leakyrelu_alpha)(encoder6)\n\n    # 7th Convolutional block in the encoder network\n    encoder7 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same',\n                             strides=strides)(encoder6)\n    encoder7 = BatchNormalization()(encoder7)\n    encoder7 = LeakyReLU(alpha=leakyrelu_alpha)(encoder7)\n    # 8th Convolutional block in the encoder network\n    encoder8 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same',\n                             strides=strides)(encoder7)\n    encoder8 = BatchNormalization()(encoder8)\n    encoder8 = LeakyReLU(alpha=leakyrelu_alpha)(encoder8)\n\n    # Decoder Network\n\n    # 1st Upsampling Convolutional Block in the decoder network\n    decoder1 = UpSampling2D(size=upsampling_size)(encoder8)\n    decoder1 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same')(decoder1)\n    decoder1 = BatchNormalization()(decoder1)\n    decoder1 = Dropout(dropout)(decoder1)\n    decoder1 = concatenate([decoder1, encoder7], axis=3)\n    decoder1 = LeakyReLU(alpha=leakyrelu_alpha)(decoder1)\n\n    # 2nd Upsampling Convolutional block in the decoder network\n    decoder2 = UpSampling2D(size=upsampling_size)(decoder1)\n    decoder2 = Convolution2D(filters=1024, kernel_size=kernel_size, padding='same')(decoder2)\n    decoder2 = BatchNormalization()(decoder2)\n    decoder2 = Dropout(dropout)(decoder2)\n    decoder2 = concatenate([decoder2, encoder6])\n    decoder2 = LeakyReLU(alpha=leakyrelu_alpha)(decoder2)\n\n    # 3rd Upsampling Convolutional block in the decoder network\n    decoder3 = UpSampling2D(size=upsampling_size)(decoder2)\n    decoder3 = Convolution2D(filters=1024, kernel_size=kernel_size, padding='same')(decoder3)\n    decoder3 = BatchNormalization()(decoder3)\n    decoder3 = Dropout(dropout)(decoder3)\n    decoder3 = concatenate([decoder3, encoder5])\n    decoder3 = LeakyReLU(alpha=leakyrelu_alpha)(decoder3)\n    # 4th Upsampling Convolutional block in the decoder network\n    decoder4 = UpSampling2D(size=upsampling_size)(decoder3)\n    decoder4 = Convolution2D(filters=1024, kernel_size=kernel_size, padding='same')(decoder4)\n    decoder4 = BatchNormalization()(decoder4)\n    decoder4 = concatenate([decoder4, encoder4])\n    decoder4 = LeakyReLU(alpha=leakyrelu_alpha)(decoder4)\n\n    # 5th Upsampling Convolutional block in the decoder network\n    decoder5 = UpSampling2D(size=upsampling_size)(decoder4)\n    decoder5 = Convolution2D(filters=1024, kernel_size=kernel_size, padding='same')(decoder5)\n    decoder5 = BatchNormalization()(decoder5)\n    decoder5 = concatenate([decoder5, encoder3])\n    decoder5 = LeakyReLU(alpha=leakyrelu_alpha)(decoder5)\n\n    # 6th Upsampling Convolutional block in the decoder network\n    decoder6 = UpSampling2D(size=upsampling_size)(decoder5)\n    decoder6 = Convolution2D(filters=512, kernel_size=kernel_size, padding='same')(decoder6)\n    decoder6 = BatchNormalization()(decoder6)\n    decoder6 = concatenate([decoder6, encoder2])\n    decoder6 = LeakyReLU(alpha=leakyrelu_alpha)(decoder6)\n\n    # 7th Upsampling Convolutional block in the decoder network\n    decoder7 = UpSampling2D(size=upsampling_size)(decoder6)\n    decoder7 = Convolution2D(filters=256, kernel_size=kernel_size, padding='same')(decoder7)\n    decoder7 = BatchNormalization()(decoder7)\n    decoder7 = concatenate([decoder7, encoder1])\n    decoder7 = LeakyReLU(alpha=leakyrelu_alpha)(decoder7)\n    # Last Convolutional layer\n    decoder8 = UpSampling2D(size=upsampling_size)(decoder7)\n    decoder8 = Convolution2D(filters=output_channels, kernel_size=kernel_size, padding='same')(decoder8)\n    decoder8 = Activation('tanh')(decoder8)\n\n    model = Model(inputs=[input_layer], outputs=[decoder8])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef build_patchgan_discriminator():\n    \"\"\"\n    Create the PatchGAN discriminator using the hyperparameter values defined below\n    \"\"\"\n    kernel_size = 4\n    strides = 2\n    leakyrelu_alpha = 0.1\n    padding = 'same'\n    num_filters_start = 64  # Number of filters to start with\n    num_kernels = 100\n    kernel_dim = 5\n    patchgan_output_dim = (256, 256, 1)\n    patchgan_patch_dim = (256, 256, 1)\n    number_patches = int(\n        (patchgan_output_dim[0] / patchgan_patch_dim[0]) * (patchgan_output_dim[1] / patchgan_patch_dim[1]))\n\n    input_layer = Input(shape=patchgan_patch_dim)\n\n    des = Convolution2D(filters=64, kernel_size=kernel_size, padding=padding, strides=strides)(input_layer)\n    des = LeakyReLU(alpha=leakyrelu_alpha)(des)\n\n    # Calculate the number of convolutional layers\n    total_conv_layers = int(np.floor(np.log(patchgan_output_dim[1]) / np.log(2)))\n    list_filters = [num_filters_start * min(total_conv_layers, (2 ** i)) for i in range(total_conv_layers)]\n    # Next 7 Convolutional blocks\n    for filters in list_filters[1:]:\n        des = Convolution2D(filters=filters, kernel_size=kernel_size, padding=padding, strides=strides)(des)\n        des = BatchNormalization()(des)\n        des = LeakyReLU(alpha=leakyrelu_alpha)(des)\n\n    # Add a flatten layer\n    flatten_layer = Flatten()(des)\n\n    # Add the final dense layer\n    dense_layer = Dense(units=2, activation='softmax')(flatten_layer)\n\n    # Create the PatchGAN model\n    model_patch_gan = Model(inputs=[input_layer], outputs=[dense_layer, flatten_layer])\n\n    # Create a list of input layers equal to the number of patches\n    list_input_layers = [Input(shape=patchgan_patch_dim) for _ in range(number_patches)]\n\n    # Pass the patches through the PatchGAN network\n    output1 = [model_patch_gan(patch)[0] for patch in list_input_layers]\n    output2 = [model_patch_gan(patch)[1] for patch in list_input_layers]\n\n    # In case of multiple patches, concatenate outputs to calculate perceptual loss\n    if len(output1) > 1:\n        output1 = concatenate(output1)\n    else:\n        output1 = output1[0]\n    # In case of multiple patches, merge output2 as well\n    if len(output2) > 1:\n        output2 = concatenate(output2)\n    else:\n        output2 = output2[0]\n\n    # Add a dense layer\n    dense_layer2 = Dense(num_kernels * kernel_dim, use_bias=False, activation=None)\n\n    # Add a lambda layer\n    custom_loss_layer = Lambda(lambda x: K.sum(\n        K.exp(-K.sum(K.abs(K.expand_dims(x, 3) - K.expand_dims(K.permute_dimensions(x, pattern=(1, 2, 0)), 0)), 2)), 2))\n\n    # Pass the output2 tensor through dense_layer2\n    output2 = dense_layer2(output2)\n\n    # Reshape the output2 tensor\n    output2 = Reshape((num_kernels, kernel_dim))(output2)\n\n    # Pass the output2 tensor through the custom_loss_layer\n    output2 = custom_loss_layer(output2)\n\n    # Finally concatenate output1 and output2\n    output1 = concatenate([output1, output2])\n    final_output = Dense(2, activation=\"softmax\")(output1)\n\n    # Create a discriminator model\n    discriminator = Model(inputs=list_input_layers, outputs=[final_output])\n    return discriminator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_adversarial_model(generator, discriminator):\n    \"\"\"\n    Create an adversarial model\n    \"\"\"\n    input_image_dim = (256, 256, 1)\n    patch_dim = (256, 256)\n\n    # Create an input layer\n    input_layer = Input(shape=input_image_dim)\n\n    # Use the generator network to generate images\n    generated_images = generator(input_layer)\n\n    # Extract patches from the generated images\n    img_height, img_width = input_img_dim[:2]\n    patch_height, patch_width = patch_dim\n\n    row_idx_list = [(i * patch_height, (i + 1) * patch_height) for i in range(int(img_height / patch_height))]\n    column_idx_list = [(i * patch_width, (i + 1) * patch_width) for i in range(int(img_width / patch_width))]\n\n    generated_patches_list = []\n    for row_idx in row_idx_list:\n        for column_idx in column_idx_list:\n            generated_patches_list.append(Lambda(lambda z: z[:, column_idx[0]:column_idx[1], row_idx[0]:row_idx[1], :],\n                                                 output_shape=input_img_dim)(generated_images))\n\n    discriminator.trainable = False\n\n    # Pass the generated patches through the discriminator network\n    dis_output = discriminator(generated_patches_list)\n\n    # Create a model\n    model = Model(inputs=[input_layer], outputs=[generated_images, dis_output])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 100\nnum_images_per_epoch = 400\nbatch_size = 10\nimg_width = 256\nimg_height = 256\nnum_channels = 1\ninput_img_dim = (256, 256, 1)\npatch_dim = (256, 256)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"common_optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999,epsilon=1e-08)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"patchgan_discriminator = build_patchgan_discriminator()\npatchgan_discriminator.compile(loss='binary_crossentropy', optimizer=common_optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_bw_image(img, path):\n    \"\"\"\n    Save a black and white image\n    \"\"\"\n    img= img.squeeze()\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1)\n    ax.imshow(img, cmap='gray', interpolation='nearest')\n    ax.axis(\"off\")\n    ax.set_title(\"Image\")\n    plt.savefig(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize_rgb(img):\n    \"\"\"\n    Visualize a rgb image\n    :param img: RGB image\n    \"\"\"\n    \n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1)\n    ax.imshow(img)\n    ax.axis(\"off\")\n    ax.set_title(\"Image\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_images(real_images, real_sketches, generated_images, num_epoch, dataset_name, limit):\n    real_sketches = real_sketches * 255.0\n    real_images = real_images * 255.0\n    generated_images = generated_images * 255.0\n\n    # Save some images only\n    real_sketches = real_sketches[:limit]\n    generated_images = generated_images[:limit]\n    real_images = real_images[:limit]\n\n    # Create a stack of images\n    X = np.hstack((real_sketches, generated_images, real_images))\n\n    # Save stack of images\n    imwrite('results/X_full_{}_{}.png'.format(dataset_name, num_epoch), X[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_and_extract_patches(images, facades, generator_model, batch_counter, patch_dim):\n    # Alternatively, train the discriminator network on real and generated images\n    if batch_counter % 2 == 0:\n        # Generate fake images\n        output_images = generator_model.predict(facades)\n\n        # Create a batch of ground truth labels\n        labels = np.zeros((output_images.shape[0], 2), dtype=np.uint8)\n        labels[:, 0] = 1\n\n    else:\n        # Take real images\n        output_images = images\n\n        # Create a batch of ground truth labels\n        labels = np.zeros((output_images.shape[0], 2), dtype=np.uint8)\n        labels[:, 1] = 1\n\n    patches = []\n    for y in range(0, output_images.shape[0], patch_dim[0]):\n        for x in range(0, output_images.shape[1], patch_dim[1]):\n            image_patches = output_images[:, y: y + patch_dim[0], x: x + patch_dim[1], :]\n            patches.append(np.asarray(image_patches, dtype=np.float32))\n\n    return patches, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unet_generator = build_unet_generator()\nunet_generator.compile(loss='mae', optimizer=common_optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adversarial_model = build_adversarial_model(unet_generator, patchgan_discriminator)\nadversarial_model.compile(loss=['mae', 'binary_crossentropy'], loss_weights=[1E2, 1], optimizer=common_optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time.time()))\ntensorboard.set_model(unet_generator)\ntensorboard.set_model(patchgan_discriminator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs=200","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print('Starting the training...')\n#     for epoch in range(0, epochs):\n#         print('Epoch {}'.format(epoch))\n# #         learning_rate=learning_rate/(1+(epoch*alpha)\n#         dis_losses = []\n#         gen_losses = []\n\n#         batch_counter = 1\n#         start = time.time()\n\n#         num_batches = int(training_facade_photos.shape[0] / batch_size)\n\n#         # Train the networks for number of batches\n#         for index in range(int(training_facade_photos.shape[0] / batch_size)):\n#             print(\"Batch:{}\".format(index))\n\n#             # Sample a batch of training and validation images\n#             train_facades_batch = training_facade_labels[index * batch_size:(index + 1) * batch_size]\n#             train_images_batch = training_facade_photos[index * batch_size:(index + 1) * batch_size]\n\n#             val_facades_batch = validation_facade_labels[index * batch_size:(index + 1) * batch_size]\n#             val_images_batch = validation_facade_photos[index * batch_size:(index + 1) * batch_size]\n\n#             patches, labels = generate_and_extract_patches(train_images_batch, train_facades_batch, unet_generator,\n#                                                            batch_counter, patch_dim)\n#             \"\"\"\n#             Train the discriminator model\n#             \"\"\"\n#             d_loss = patchgan_discriminator.train_on_batch(patches, labels)\n\n#             labels = np.zeros((train_images_batch.shape[0], 2), dtype=np.uint8)\n#             labels[:, 1] = 1\n\n#             \"\"\"\n#             Train the adversarial model\n#             \"\"\"\n#             g_loss = adversarial_model.train_on_batch(train_facades_batch, [train_images_batch, labels])\n\n#             # Increase the batch counter\n#             batch_counter += 1\n\n#             print(\"Discriminator loss:\", d_loss)\n#             print(\"Generator loss:\", g_loss)\n\n#             gen_losses.append(g_loss[1])\n#             dis_losses.append(d_loss)\n\n# #         \"\"\"\n# #         Save losses to Tensorboard after each epoch\n# #         \"\"\"\n# #         write_log(tensorboard, 'discriminator_loss', np.mean(dis_losses), epoch)\n# #         write_log(tensorboard, 'generator_loss', np.mean(gen_losses), epoch)\n#         # After every 2nd epoch, generate and save images for visualization\n#         if epoch % 2 == 0:\n#             # Sample a batch of validation datasets\n#             val_facades_batch = validation_facade_labels[0:5]\n#             val_images_batch = validation_facade_photos[0:5]\n\n#             # Generate images\n#             validation_generated_images = unet_generator.predict(val_facades_batch)\n\n#             #print(validation_generated_images[0])\n            \n#             for x in range (5):\n#                 print(\"facade label:-\")\n#                 visualize_bw_image(val_facades_batch[x])\n#                 print(\"facade real_image:-\")\n#                 visualize_bw_image(val_images_batch[x])\n#                 print(\"facade generated_image:-\")\n#                 visualize_bw_image(validation_generated_images[x])\n\n\n#             # Save images\n#             save_images(val_images_batch, val_facades_batch, validation_generated_images, epoch, 'validation', limit=5)\n\n#     # Save models\n#     unet_generator.save_weights(\"generator.h5\")\n#     patchgan_discriminator.save_weights(\"discriminator.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    print('Starting the training...')\n    for epoch in range(0, epochs):\n        print('Epoch {}'.format(epoch))\n\n        dis_losses = []\n        gen_losses = []\n\n        batch_counter = 1\n        start = time.time()\n\n        num_batches = int(training_facade_photos.shape[0] / batch_size)\n\n        # Train the networks for number of batches\n        for index in range(int(training_facade_photos.shape[0] / batch_size)):\n            print(\"Batch:{}\".format(index))\n\n            # Sample a batch of training and validation images\n            train_facades_batch = training_facade_labels[index * batch_size:(index + 1) * batch_size]\n            train_images_batch = training_facade_photos[index * batch_size:(index + 1) * batch_size]\n\n            val_facades_batch = validation_facade_labels[index * batch_size:(index + 1) * batch_size]\n            val_images_batch = validation_facade_photos[index * batch_size:(index + 1) * batch_size]\n\n            patches, labels = generate_and_extract_patches(train_images_batch, train_facades_batch, unet_generator,\n                                                           batch_counter, patch_dim)\n\n            \"\"\"\n            Train the discriminator model\n            \"\"\"\n            d_loss = patchgan_discriminator.train_on_batch(patches, labels)\n\n            labels = np.zeros((train_images_batch.shape[0], 2), dtype=np.uint8)\n            labels[:, 1] = 1\n\n            \"\"\"\n            Train the adversarial model\n            \"\"\"\n            g_loss = adversarial_model.train_on_batch(train_facades_batch, [train_images_batch, labels])\n\n            # Increase the batch counter\n            batch_counter += 1\n\n            print(\"Discriminator loss:\", d_loss)\n            print(\"Generator loss:\", g_loss)\n\n            gen_losses.append(g_loss[1])\n            dis_losses.append(d_loss)\n\n        \"\"\"\n        Save losses to Tensorboard after each epoch\n        \"\"\"\n#         write_log(tensorboard, 'discriminator_loss', np.mean(dis_losses), epoch)\n#         write_log(tensorboard, 'generator_loss', np.mean(gen_losses), epoch)\n\n        # After every 10th epoch, generate and save images for visualization\n        if epoch % 2 == 0:\n            # Sample a batch of validation datasets\n            val_facades_batch = validation_facade_labels[0:5]\n            val_images_batch = validation_facade_photos[0:5]\n\n            # Generate images\n            validation_generated_images = unet_generator.predict(val_facades_batch)\n            for x in range (5):\n                print(\"facade label:-\")\n                visualize_bw_image(val_facades_batch[x])\n                print(\"facade real_image:-\")\n                visualize_bw_image(val_images_batch[x])\n                print(\"facade generated_image:-\")\n                visualize_bw_image(validation_generated_images[x])\n\n            # Save images\n            save_images(val_images_batch, val_facades_batch, validation_generated_images, epoch, 'validation', limit=5)\n\n    # Save models\n    unet_generator.save_weights(\"generator.h5\")\n    patchgan_discriminator.save_weights(\"discriminator.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}